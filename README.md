# ğŸš€ Elyx Hackathon â€“ Data Generator  

This project generates an **8-month WhatsApp-style conversation dataset** for the Elyx health platform.  
It simulates realistic interactions between a member (**Rohan Patel**) and advisors (**Ruby, Dr_Warren, Advik**), including onboarding, medical plans, test scheduling, exercise updates, travel, adherence, and Q&A.  

---
## Tech_Architecture:

+------------------+       +-------------------------+
|   Streamlit UI   | <---> |   data_generator.py     |
|  (app.py)        |       |  (message + rationale)  |
+------------------+       +-------------------------+
           |                           |
           v                           v
+------------------+         +----------------------+
|  model_integration| -----> |   Local LLM (Mistral)|
|  (llama_cpp API) |         |   GGUF Quantized     |
+------------------+         +----------------------+
           |
           v
+-------------------+
|  JSON Outputs     |
|  (messages +      |
|   decisions)      |
+-------------------+

---

## âš¡ Quick Start  

1. **Clone the repository:**  
   ```bash
   git clone https://github.com/AvTar-1/Elyx.git
   cd Elyx
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Streamlit app:**

   ```bash
   streamlit run app.py
   ```

---

## âœ¨ Features

* ğŸ¤– **Local LLM Integration**: Runs on **Mistral-7B** via `llama_cpp`
* ğŸ§© **Rich Context**: Each message considers date, week, travel, and past context
* ğŸ² **Randomized Conversations**: Member and advisor questions are diverse and deduplicated
* ğŸ©º **Clinical Realism**: Plans, tests, and decisions appear at realistic intervals
* ğŸ“‚ **Structured Outputs**:

  * `data/messages.json` â†’ Full conversation timeline
  * `decisions/<id>.json` â†’ Clinical rationale for each decision

---

## ğŸ“Š Example Timeline

```
2025-01-01 00:00 â€” Ruby â€” tags: [ONBOARD]
Hi Rohan Patel, welcome to Elyx! We'll check-in regularly.

2025-01-01 01:00 â€” Dr_Warren â€” tags: [PLAN]
Initial medical plan prepared. Baseline tests scheduled.

2025-01-02 08:30 â€” Advik â€” tags: [EXERCISE]
Donâ€™t forget your morning walk today. 15 minutes is a great start!
```

---

## ğŸ› ï¸ Tech Stack

* ğŸ¨ **Frontend**: Streamlit
* ğŸ **Backend**: Python 3.10+
* ğŸ§  **LLM**: Mistral-7B-Instruct (GGUF quantized)
* ğŸ“¦ **Libraries**: streamlit, llama-cpp-python, huggingface\_hub

---

## ğŸš€ Usage

1. **Place your model (.gguf file)** in the `models/` folder or set the environment variable:

   ```bash
   setx LLAMA_GGUF_PATH models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
   ```

2. **Run the generator:**

   ```bash
   python data_generator.py
   ```

3. **Explore conversations in the UI:**

   ```bash
   streamlit run app.py
   ```

---

## ğŸ“‚ Key Files

* `data_generator.py` â†’ Message and rationale generation
* `prompts/` â†’ Prompt templates (message, rationale, paraphrase)
* `model_integration_local.py` â†’ Local LLM wrapper
* `app.py` â†’ Streamlit exploration UI

---

## ğŸ¯ Future Roadmap

* ğŸŒ Multi-language conversations
* ğŸ“Š Analytics dashboard for clinicians
* ğŸ§‘â€ğŸ¤â€ğŸ§‘ User profiles and personalization
* â±ï¸ Real-time chat mode

---

## ğŸ“œ License

MIT License

---

ğŸ™Œ *Built for Elyx Hackathon 2025 â€” combining AI, healthcare, and human touch.*

```

---

